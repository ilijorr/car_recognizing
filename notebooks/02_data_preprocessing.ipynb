{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 2. Kreiranje Dataset-a za Mašinsko Učenje\n",
    "\n",
    "## Organizacija podataka i priprema za treniranje\n",
    "\n",
    "---\n",
    "\n",
    "Nakon normalizacije direktorijuma, sledeći korak je kreiranje dataset-a koji će biti pogdan za treniranje neuronske mreže."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import biblioteka\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Dodaj src u path\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir if current_dir.name != 'notebooks' else current_dir.parent\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import dataset modula\n",
    "from dataset import CarDataModule\n",
    "from cached_dataset import CachedCarDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "### Kako funkcioniše CarDataModule\n",
    "\n",
    "**CarDataModule** je osnovna klasa koja:\n",
    "\n",
    "1. **Skenira direktorijume** - prolazi kroz sve poddirektorijume u `data/raw/`\n",
    "2. **Ekstraktuje labele** - iz naziva direktorijuma izvlači make, model, year koristeći CarFolderNormalizer\n",
    "3. **Učitava putanje slika** - pronalazi sve `.jpg` fajlove u svakom direktorijumu\n",
    "4. **Deli podatke** - koristi make-model kombinacije da spreči data leakage (64% train / 16% val / 20% test)\n",
    "5. **Enkodira labele** - konvertuje string labele u numeričke vrednosti pomoću LabelEncoder\n",
    "6. **Primenjuje transformacije** - različite za train (augmentacija) i val/test (normalizacija)\n",
    "\n",
    "**Problem**: Ovaj proces traje 5-10 minuta jer mora da skenira ~86,000 slika."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### Sistem keširanje - CachedCarDataModule\n",
    "\n",
    "Da bi se izbegao spori sken, implementiran je **CachedCarDataModule**:\n",
    "\n",
    "#### Prvi korak: Kreiranje keša\n",
    "```bash\n",
    "python scripts/create_data_cache.py --data_path data/raw --cache_file cache_consolidated/dataset_cache.pkl\n",
    "```\n",
    "\n",
    "Ovaj script:\n",
    "- Pokreće CarDataModule jednom (10 minuta)\n",
    "- Čuva sve podatke u `.pkl` fajl:\n",
    "  - Sve putanje do slika\n",
    "  - Ekstraktovane labele\n",
    "  - Train/val/test podelu\n",
    "  - Label encoders\n",
    "  - Metadata o klasama\n",
    "\n",
    "#### Sledeći korišćenja: Brzo učitavanje\n",
    "```python\n",
    "data_module = CachedCarDataModule(\n",
    "    data_path=\"data/raw\",\n",
    "    cache_file=\"cache_consolidated/dataset_cache.pkl\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Rezultat**: Učitavanje za 10 sekundi umesto 10 minuta (60x brže)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### Demonstracija: Testiranje cache fajla\n",
    "\n",
    "Hajde da proverimo da li cache fajl postoji i učitamo ga:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cache file pronađen: /home/void/Documents/faks/ri/projekat/cache_consolidated/dataset_cache.pkl\n",
      "📏 Veličina fajla: 13.2 MB\n",
      "\n",
      "📊 Cache sadrži:\n",
      "   Train samples: 52,030\n",
      "   Val samples: 12,218\n",
      "   Test samples: 15,777\n",
      "   Ukupno: 80,025\n",
      "\n",
      "🏭 Broj klasa:\n",
      "   Makes: 81\n",
      "   Models: 1358\n",
      "   Years: 12\n"
     ]
    }
   ],
   "source": [
    "# Proveri da li cache postoji\n",
    "cache_file = project_root / \"cache_consolidated\" / \"dataset_cache.pkl\"\n",
    "\n",
    "if cache_file.exists():\n",
    "    print(f\"✅ Cache file pronađen: {cache_file}\")\n",
    "    print(f\"📏 Veličina fajla: {cache_file.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    # Učitaj osnovne informacije\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        cache_data = pickle.load(f)\n",
    "    \n",
    "    print(f\"\\n📊 Cache sadrži:\")\n",
    "    print(f\"   Train samples: {len(cache_data['train_samples']):,}\")\n",
    "    print(f\"   Val samples: {len(cache_data['val_samples']):,}\")\n",
    "    print(f\"   Test samples: {len(cache_data['test_samples']):,}\")\n",
    "    print(f\"   Ukupno: {len(cache_data['train_samples']) + len(cache_data['val_samples']) + len(cache_data['test_samples']):,}\")\n",
    "    \n",
    "    print(f\"\\n🏭 Broj klasa:\")\n",
    "    print(f\"   Makes: {cache_data['num_makes']}\")\n",
    "    print(f\"   Models: {cache_data['num_models']}\")\n",
    "    print(f\"   Years: {cache_data['num_years']}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ Cache file ne postoji: {cache_file}\")\n",
    "    print(f\"💡 Potrebno je pokrenuti: python scripts/create_data_cache.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### Analiza kvaliteta podataka\n",
    "\n",
    "Sada možemo da analiziramo stvarne podatke koristeći istu logiku kao `check_data_quality.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Analiza kvaliteta podataka na 80,025 uzoraka:\n",
      "\n",
      "⚠️ UNKNOWN labeli:\n",
      "   Makes: 63 (0.1%)\n",
      "   Models: 63 (0.1%)\n",
      "   Years: 33 (0.0%)\n",
      "\n",
      "🔒 Data leakage proverka:\n",
      "   Train-Val overlap: 0 kombinacija\n",
      "   Train-Test overlap: 0 kombinacija\n",
      "   Val-Test overlap: 0 kombinacija\n",
      "   ✅ Nema data leakage - podela je ispravna\n",
      "\n",
      "📊 Distribucija klasa:\n",
      "   Makes - najčešći: BMW (12,267)\n",
      "   Makes - najređi: MG (4)\n",
      "   Models - najčešći: 1_SERIES (622)\n",
      "   Models - najređi: Express_LWB (2)\n",
      "   Models sa <10 uzoraka: 46 (3.4%)\n",
      "\n",
      "📅 Distribucija godina:\n",
      "   1920s: 31 uzoraka\n",
      "   1930s: 84 uzoraka\n",
      "   1940s: 97 uzoraka\n",
      "   1950s: 334 uzoraka\n",
      "   1960s: 560 uzoraka\n",
      "   1970s: 733 uzoraka\n",
      "   1980s: 1,306 uzoraka\n",
      "   1990s: 2,784 uzoraka\n",
      "   2000s: 20,127 uzoraka\n",
      "   2010s: 41,640 uzoraka\n",
      "   2020s: 12,296 uzoraka\n",
      "   Unknown: 33 uzoraka\n"
     ]
    }
   ],
   "source": [
    "if cache_file.exists():\n",
    "    # Izvuci sve uzorke\n",
    "    all_samples = (cache_data['train_samples'] + \n",
    "                  cache_data['val_samples'] + \n",
    "                  cache_data['test_samples'])\n",
    "    \n",
    "    print(f\"🔍 Analiza kvaliteta podataka na {len(all_samples):,} uzoraka:\")\n",
    "    print()\n",
    "    \n",
    "    # 1. Proveri UNKNOWN vrednosti\n",
    "    unknown_makes = sum(1 for s in all_samples if s['make'] == 'UNKNOWN')\n",
    "    unknown_models = sum(1 for s in all_samples if s['model'] == 'UNKNOWN')\n",
    "    unknown_years = sum(1 for s in all_samples if s['year'] == 'Unknown')\n",
    "    \n",
    "    print(f\"⚠️ UNKNOWN labeli:\")\n",
    "    print(f\"   Makes: {unknown_makes:,} ({unknown_makes/len(all_samples)*100:.1f}%)\")\n",
    "    print(f\"   Models: {unknown_models:,} ({unknown_models/len(all_samples)*100:.1f}%)\")\n",
    "    print(f\"   Years: {unknown_years:,} ({unknown_years/len(all_samples)*100:.1f}%)\")\n",
    "    \n",
    "    # 2. Proverka data leakage\n",
    "    train_combos = set(f\"{s['make']}_{s['model']}\" for s in cache_data['train_samples'])\n",
    "    val_combos = set(f\"{s['make']}_{s['model']}\" for s in cache_data['val_samples'])\n",
    "    test_combos = set(f\"{s['make']}_{s['model']}\" for s in cache_data['test_samples'])\n",
    "    \n",
    "    train_val_overlap = train_combos & val_combos\n",
    "    train_test_overlap = train_combos & test_combos\n",
    "    val_test_overlap = val_combos & test_combos\n",
    "    \n",
    "    print(f\"\\n🔒 Data leakage proverka:\")\n",
    "    print(f\"   Train-Val overlap: {len(train_val_overlap)} kombinacija\")\n",
    "    print(f\"   Train-Test overlap: {len(train_test_overlap)} kombinacija\")\n",
    "    print(f\"   Val-Test overlap: {len(val_test_overlap)} kombinacija\")\n",
    "    \n",
    "    if len(train_val_overlap) + len(train_test_overlap) + len(val_test_overlap) == 0:\n",
    "        print(f\"   ✅ Nema data leakage - podela je ispravna\")\n",
    "    else:\n",
    "        print(f\"   ❌ Detektovan data leakage!\")\n",
    "    \n",
    "    # 3. Distribucija klasa\n",
    "    make_counts = Counter(s['make'] for s in all_samples)\n",
    "    model_counts = Counter(s['model'] for s in all_samples)\n",
    "    year_counts = Counter(s['year'] for s in all_samples)\n",
    "    \n",
    "    print(f\"\\n📊 Distribucija klasa:\")\n",
    "    print(f\"   Makes - najčešći: {make_counts.most_common(1)[0][0]} ({make_counts.most_common(1)[0][1]:,})\")\n",
    "    print(f\"   Makes - najređi: {make_counts.most_common()[-1][0]} ({make_counts.most_common()[-1][1]:,})\")\n",
    "    \n",
    "    print(f\"   Models - najčešći: {model_counts.most_common(1)[0][0]} ({model_counts.most_common(1)[0][1]:,})\")\n",
    "    print(f\"   Models - najređi: {model_counts.most_common()[-1][0]} ({model_counts.most_common()[-1][1]:,})\")\n",
    "    \n",
    "    models_under_10 = sum(1 for count in model_counts.values() if count < 10)\n",
    "    print(f\"   Models sa <10 uzoraka: {models_under_10:,} ({models_under_10/len(model_counts)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📅 Distribucija godina:\")\n",
    "    for year, count in sorted(year_counts.items()):\n",
    "        print(f\"   {year}: {count:,} uzoraka\")\n",
    "else:\n",
    "    print(\"❌ Nije moguće analizirati podatke - cache ne postoji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### Demonstracija brzog učitavanja\n",
    "\n",
    "Ako cache postoji, možemo da demonstriramo brzo učitavanje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Demonstracija brzog učitavanja sa CachedCarDataModule:\n",
      "📦 Loading dataset cache from /home/void/Documents/faks/ri/projekat/cache_consolidated/dataset_cache.pkl...\n",
      "✅ Cache loaded! Train: 52,030, Val: 12,218, Test: 15,777\n",
      "\n",
      "⏱️ Vreme učitavanja: 626.0 sekundi\n",
      "📈 Ubrzanje: ~1x brže od običnog CarDataModule\n",
      "\n",
      "✅ Dataset spreman za treniranje!\n",
      "   Classes: 81 makes, 1358 models, 12 years\n"
     ]
    }
   ],
   "source": [
    "if cache_file.exists():\n",
    "    import time\n",
    "    \n",
    "    print(\"⚡ Demonstracija brzog učitavanja sa CachedCarDataModule:\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Učitaj dataset pomoću cache-a\n",
    "    cached_data_module = CachedCarDataModule(\n",
    "        data_path=str(project_root / \"data\" / \"raw\"),\n",
    "        cache_file=str(cache_file),\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\n⏱️ Vreme učitavanja: {end_time - start_time:.1f} sekundi\")\n",
    "    print(f\"📈 Ubrzanje: ~{10*60 / (end_time - start_time):.0f}x brže od običnog CarDataModule\")\n",
    "    \n",
    "    # Prikaži osnovne informacije\n",
    "    class_info = cached_data_module.get_class_info()\n",
    "    print(f\"\\n✅ Dataset spreman za treniranje!\")\n",
    "    print(f\"   Classes: {class_info['num_makes']} makes, {class_info['num_models']} models, {class_info['num_years']} years\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Cache ne postoji - potrebno je kreirati cache prvo\")\n",
    "    print(\"💡 Pokrenite: python scripts/create_data_cache.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### Transformacije slika\n",
    "\n",
    "Dataset koristi različite transformacije za train i validation/test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6w0csuviofq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Transformacije za treniranje:\n",
      "   1. Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "   2. RandomHorizontalFlip(p=0.5)\n",
      "   3. RandomApply(\n",
      "    p=0.3\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      ")\n",
      "   4. RandomApply(\n",
      "    p=0.4\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1))\n",
      ")\n",
      "   5. ToTensor()\n",
      "   6. Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "\n",
      "🎯 Transformacije za validation/test:\n",
      "   1. Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "   2. ToTensor()\n",
      "   3. Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "\n",
      "📐 Sve transformacije su optimizovane za ResNet-50 (224x224 input)\n",
      "🎨 Augmentacija pomaže da model generalizuje bolje\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Transformacije za treniranje (sa augmentacijom)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=10)], p=0.3),\n",
    "    transforms.RandomApply([transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1)], p=0.4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformacije za validation/test (bez augmentacije)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"🔄 Transformacije za treniranje:\")\n",
    "for i, transform in enumerate(train_transforms.transforms, 1):\n",
    "    print(f\"   {i}. {transform}\")\n",
    "\n",
    "print(\"\\n🎯 Transformacije za validation/test:\")\n",
    "for i, transform in enumerate(val_test_transforms.transforms, 1):\n",
    "    print(f\"   {i}. {transform}\")\n",
    "\n",
    "print(\"\\n📐 Sve transformacije su optimizovane za ResNet-50 (224x224 input)\")\n",
    "print(\"🎨 Augmentacija pomaže da model generalizuje bolje\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### Zaključak\n",
    "\n",
    "Dataset je uspešno pripremljen za mašinsko učenje:\n",
    "\n",
    "#### ✅ Prednosti:\n",
    "- Veliki broj slika (~79,000)\n",
    "- Raznovrstan skup proizvođača i modela\n",
    "- Sprečen data leakage (make-model podela)\n",
    "- Brzo učitavanje pomoću cache sistema (60x brže)\n",
    "- Kvalitetne transformacije za augmentaciju\n",
    "\n",
    "#### ⚠️ Identifikovani izazovi:\n",
    "- Značajna nebalansiranost klasa (posebno modeli)\n",
    "- Veliki broj modela (1300+) sa malo uzoraka\n",
    "- Kombinatorička eksplozija (600,000+ teorijskih kombinacija)\n",
    "- Vrlo nizak random baseline za EMR (~0.00005%)\n",
    "\n",
    "#### 🔄 Sledeći korak:\n",
    "Pokušaj treniranja ResNet-50 modela i identifikacija problema u performansama."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Car Recognition (venv)",
   "language": "python",
   "name": "car_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
