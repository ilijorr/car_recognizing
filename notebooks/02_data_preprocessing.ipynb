{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 2. Kreiranje Dataset-a za MaÅ¡insko UÄenje\n",
    "\n",
    "## Organizacija podataka i priprema za treniranje\n",
    "\n",
    "---\n",
    "\n",
    "Nakon normalizacije direktorijuma, sledeÄ‡i korak je kreiranje dataset-a koji Ä‡e biti pogdan za treniranje neuronske mreÅ¾e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import biblioteka\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Dodaj src u path\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir if current_dir.name != 'notebooks' else current_dir.parent\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import dataset modula\n",
    "from dataset import CarDataModule\n",
    "from cached_dataset import CachedCarDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "### Kako funkcioniÅ¡e CarDataModule\n",
    "\n",
    "**CarDataModule** je osnovna klasa koja:\n",
    "\n",
    "1. **Skenira direktorijume** - prolazi kroz sve poddirektorijume u `data/raw/`\n",
    "2. **Ekstraktuje labele** - iz naziva direktorijuma izvlaÄi make, model, year koristeÄ‡i CarFolderNormalizer\n",
    "3. **UÄitava putanje slika** - pronalazi sve `.jpg` fajlove u svakom direktorijumu\n",
    "4. **Deli podatke** - koristi make-model kombinacije da spreÄi data leakage (64% train / 16% val / 20% test)\n",
    "5. **Enkodira labele** - konvertuje string labele u numeriÄke vrednosti pomoÄ‡u LabelEncoder\n",
    "6. **Primenjuje transformacije** - razliÄite za train (augmentacija) i val/test (normalizacija)\n",
    "\n",
    "**Problem**: Ovaj proces traje 5-10 minuta jer mora da skenira ~86,000 slika."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### Sistem keÅ¡iranje - CachedCarDataModule\n",
    "\n",
    "Da bi se izbegao spori sken, implementiran je **CachedCarDataModule**:\n",
    "\n",
    "#### Prvi korak: Kreiranje keÅ¡a\n",
    "```bash\n",
    "python scripts/create_data_cache.py --data_path data/raw --cache_file cache_consolidated/dataset_cache.pkl\n",
    "```\n",
    "\n",
    "Ovaj script:\n",
    "- PokreÄ‡e CarDataModule jednom (10 minuta)\n",
    "- ÄŒuva sve podatke u `.pkl` fajl:\n",
    "  - Sve putanje do slika\n",
    "  - Ekstraktovane labele\n",
    "  - Train/val/test podelu\n",
    "  - Label encoders\n",
    "  - Metadata o klasama\n",
    "\n",
    "#### SledeÄ‡i koriÅ¡Ä‡enja: Brzo uÄitavanje\n",
    "```python\n",
    "data_module = CachedCarDataModule(\n",
    "    data_path=\"data/raw\",\n",
    "    cache_file=\"cache_consolidated/dataset_cache.pkl\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Rezultat**: UÄitavanje za 10 sekundi umesto 10 minuta (60x brÅ¾e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### Demonstracija: Testiranje cache fajla\n",
    "\n",
    "Hajde da proverimo da li cache fajl postoji i uÄitamo ga:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cache file pronaÄ‘en: /home/void/Documents/faks/ri/projekat/cache_consolidated/dataset_cache.pkl\n",
      "ğŸ“ VeliÄina fajla: 13.2 MB\n",
      "\n",
      "ğŸ“Š Cache sadrÅ¾i:\n",
      "   Train samples: 52,030\n",
      "   Val samples: 12,218\n",
      "   Test samples: 15,777\n",
      "   Ukupno: 80,025\n",
      "\n",
      "ğŸ­ Broj klasa:\n",
      "   Makes: 81\n",
      "   Models: 1358\n",
      "   Years: 12\n"
     ]
    }
   ],
   "source": [
    "# Proveri da li cache postoji\n",
    "cache_file = project_root / \"cache_consolidated\" / \"dataset_cache.pkl\"\n",
    "\n",
    "if cache_file.exists():\n",
    "    print(f\"âœ… Cache file pronaÄ‘en: {cache_file}\")\n",
    "    print(f\"ğŸ“ VeliÄina fajla: {cache_file.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    # UÄitaj osnovne informacije\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        cache_data = pickle.load(f)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Cache sadrÅ¾i:\")\n",
    "    print(f\"   Train samples: {len(cache_data['train_samples']):,}\")\n",
    "    print(f\"   Val samples: {len(cache_data['val_samples']):,}\")\n",
    "    print(f\"   Test samples: {len(cache_data['test_samples']):,}\")\n",
    "    print(f\"   Ukupno: {len(cache_data['train_samples']) + len(cache_data['val_samples']) + len(cache_data['test_samples']):,}\")\n",
    "    \n",
    "    print(f\"\\nğŸ­ Broj klasa:\")\n",
    "    print(f\"   Makes: {cache_data['num_makes']}\")\n",
    "    print(f\"   Models: {cache_data['num_models']}\")\n",
    "    print(f\"   Years: {cache_data['num_years']}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Cache file ne postoji: {cache_file}\")\n",
    "    print(f\"ğŸ’¡ Potrebno je pokrenuti: python scripts/create_data_cache.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### Analiza kvaliteta podataka\n",
    "\n",
    "Sada moÅ¾emo da analiziramo stvarne podatke koristeÄ‡i istu logiku kao `check_data_quality.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Analiza kvaliteta podataka na 80,025 uzoraka:\n",
      "\n",
      "âš ï¸ UNKNOWN labeli:\n",
      "   Makes: 63 (0.1%)\n",
      "   Models: 63 (0.1%)\n",
      "   Years: 33 (0.0%)\n",
      "\n",
      "ğŸ”’ Data leakage proverka:\n",
      "   Train-Val overlap: 0 kombinacija\n",
      "   Train-Test overlap: 0 kombinacija\n",
      "   Val-Test overlap: 0 kombinacija\n",
      "   âœ… Nema data leakage - podela je ispravna\n",
      "\n",
      "ğŸ“Š Distribucija klasa:\n",
      "   Makes - najÄeÅ¡Ä‡i: BMW (12,267)\n",
      "   Makes - najreÄ‘i: MG (4)\n",
      "   Models - najÄeÅ¡Ä‡i: 1_SERIES (622)\n",
      "   Models - najreÄ‘i: Express_LWB (2)\n",
      "   Models sa <10 uzoraka: 46 (3.4%)\n",
      "\n",
      "ğŸ“… Distribucija godina:\n",
      "   1920s: 31 uzoraka\n",
      "   1930s: 84 uzoraka\n",
      "   1940s: 97 uzoraka\n",
      "   1950s: 334 uzoraka\n",
      "   1960s: 560 uzoraka\n",
      "   1970s: 733 uzoraka\n",
      "   1980s: 1,306 uzoraka\n",
      "   1990s: 2,784 uzoraka\n",
      "   2000s: 20,127 uzoraka\n",
      "   2010s: 41,640 uzoraka\n",
      "   2020s: 12,296 uzoraka\n",
      "   Unknown: 33 uzoraka\n"
     ]
    }
   ],
   "source": [
    "if cache_file.exists():\n",
    "    # Izvuci sve uzorke\n",
    "    all_samples = (cache_data['train_samples'] + \n",
    "                  cache_data['val_samples'] + \n",
    "                  cache_data['test_samples'])\n",
    "    \n",
    "    print(f\"ğŸ” Analiza kvaliteta podataka na {len(all_samples):,} uzoraka:\")\n",
    "    print()\n",
    "    \n",
    "    # 1. Proveri UNKNOWN vrednosti\n",
    "    unknown_makes = sum(1 for s in all_samples if s['make'] == 'UNKNOWN')\n",
    "    unknown_models = sum(1 for s in all_samples if s['model'] == 'UNKNOWN')\n",
    "    unknown_years = sum(1 for s in all_samples if s['year'] == 'Unknown')\n",
    "    \n",
    "    print(f\"âš ï¸ UNKNOWN labeli:\")\n",
    "    print(f\"   Makes: {unknown_makes:,} ({unknown_makes/len(all_samples)*100:.1f}%)\")\n",
    "    print(f\"   Models: {unknown_models:,} ({unknown_models/len(all_samples)*100:.1f}%)\")\n",
    "    print(f\"   Years: {unknown_years:,} ({unknown_years/len(all_samples)*100:.1f}%)\")\n",
    "    \n",
    "    # 2. Proverka data leakage\n",
    "    train_combos = set(f\"{s['make']}_{s['model']}\" for s in cache_data['train_samples'])\n",
    "    val_combos = set(f\"{s['make']}_{s['model']}\" for s in cache_data['val_samples'])\n",
    "    test_combos = set(f\"{s['make']}_{s['model']}\" for s in cache_data['test_samples'])\n",
    "    \n",
    "    train_val_overlap = train_combos & val_combos\n",
    "    train_test_overlap = train_combos & test_combos\n",
    "    val_test_overlap = val_combos & test_combos\n",
    "    \n",
    "    print(f\"\\nğŸ”’ Data leakage proverka:\")\n",
    "    print(f\"   Train-Val overlap: {len(train_val_overlap)} kombinacija\")\n",
    "    print(f\"   Train-Test overlap: {len(train_test_overlap)} kombinacija\")\n",
    "    print(f\"   Val-Test overlap: {len(val_test_overlap)} kombinacija\")\n",
    "    \n",
    "    if len(train_val_overlap) + len(train_test_overlap) + len(val_test_overlap) == 0:\n",
    "        print(f\"   âœ… Nema data leakage - podela je ispravna\")\n",
    "    else:\n",
    "        print(f\"   âŒ Detektovan data leakage!\")\n",
    "    \n",
    "    # 3. Distribucija klasa\n",
    "    make_counts = Counter(s['make'] for s in all_samples)\n",
    "    model_counts = Counter(s['model'] for s in all_samples)\n",
    "    year_counts = Counter(s['year'] for s in all_samples)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Distribucija klasa:\")\n",
    "    print(f\"   Makes - najÄeÅ¡Ä‡i: {make_counts.most_common(1)[0][0]} ({make_counts.most_common(1)[0][1]:,})\")\n",
    "    print(f\"   Makes - najreÄ‘i: {make_counts.most_common()[-1][0]} ({make_counts.most_common()[-1][1]:,})\")\n",
    "    \n",
    "    print(f\"   Models - najÄeÅ¡Ä‡i: {model_counts.most_common(1)[0][0]} ({model_counts.most_common(1)[0][1]:,})\")\n",
    "    print(f\"   Models - najreÄ‘i: {model_counts.most_common()[-1][0]} ({model_counts.most_common()[-1][1]:,})\")\n",
    "    \n",
    "    models_under_10 = sum(1 for count in model_counts.values() if count < 10)\n",
    "    print(f\"   Models sa <10 uzoraka: {models_under_10:,} ({models_under_10/len(model_counts)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“… Distribucija godina:\")\n",
    "    for year, count in sorted(year_counts.items()):\n",
    "        print(f\"   {year}: {count:,} uzoraka\")\n",
    "else:\n",
    "    print(\"âŒ Nije moguÄ‡e analizirati podatke - cache ne postoji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### Demonstracija brzog uÄitavanja\n",
    "\n",
    "Ako cache postoji, moÅ¾emo da demonstriramo brzo uÄitavanje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Demonstracija brzog uÄitavanja sa CachedCarDataModule:\n",
      "ğŸ“¦ Loading dataset cache from /home/void/Documents/faks/ri/projekat/cache_consolidated/dataset_cache.pkl...\n",
      "âœ… Cache loaded! Train: 52,030, Val: 12,218, Test: 15,777\n",
      "\n",
      "â±ï¸ Vreme uÄitavanja: 626.0 sekundi\n",
      "ğŸ“ˆ Ubrzanje: ~1x brÅ¾e od obiÄnog CarDataModule\n",
      "\n",
      "âœ… Dataset spreman za treniranje!\n",
      "   Classes: 81 makes, 1358 models, 12 years\n"
     ]
    }
   ],
   "source": [
    "if cache_file.exists():\n",
    "    import time\n",
    "    \n",
    "    print(\"âš¡ Demonstracija brzog uÄitavanja sa CachedCarDataModule:\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # UÄitaj dataset pomoÄ‡u cache-a\n",
    "    cached_data_module = CachedCarDataModule(\n",
    "        data_path=str(project_root / \"data\" / \"raw\"),\n",
    "        cache_file=str(cache_file),\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\nâ±ï¸ Vreme uÄitavanja: {end_time - start_time:.1f} sekundi\")\n",
    "    print(f\"ğŸ“ˆ Ubrzanje: ~{10*60 / (end_time - start_time):.0f}x brÅ¾e od obiÄnog CarDataModule\")\n",
    "    \n",
    "    # PrikaÅ¾i osnovne informacije\n",
    "    class_info = cached_data_module.get_class_info()\n",
    "    print(f\"\\nâœ… Dataset spreman za treniranje!\")\n",
    "    print(f\"   Classes: {class_info['num_makes']} makes, {class_info['num_models']} models, {class_info['num_years']} years\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Cache ne postoji - potrebno je kreirati cache prvo\")\n",
    "    print(\"ğŸ’¡ Pokrenite: python scripts/create_data_cache.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### Transformacije slika\n",
    "\n",
    "Dataset koristi razliÄite transformacije za train i validation/test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6w0csuviofq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Transformacije za treniranje:\n",
      "   1. Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "   2. RandomHorizontalFlip(p=0.5)\n",
      "   3. RandomApply(\n",
      "    p=0.3\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      ")\n",
      "   4. RandomApply(\n",
      "    p=0.4\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1))\n",
      ")\n",
      "   5. ToTensor()\n",
      "   6. Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "\n",
      "ğŸ¯ Transformacije za validation/test:\n",
      "   1. Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "   2. ToTensor()\n",
      "   3. Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "\n",
      "ğŸ“ Sve transformacije su optimizovane za ResNet-50 (224x224 input)\n",
      "ğŸ¨ Augmentacija pomaÅ¾e da model generalizuje bolje\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Transformacije za treniranje (sa augmentacijom)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=10)], p=0.3),\n",
    "    transforms.RandomApply([transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1)], p=0.4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformacije za validation/test (bez augmentacije)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"ğŸ”„ Transformacije za treniranje:\")\n",
    "for i, transform in enumerate(train_transforms.transforms, 1):\n",
    "    print(f\"   {i}. {transform}\")\n",
    "\n",
    "print(\"\\nğŸ¯ Transformacije za validation/test:\")\n",
    "for i, transform in enumerate(val_test_transforms.transforms, 1):\n",
    "    print(f\"   {i}. {transform}\")\n",
    "\n",
    "print(\"\\nğŸ“ Sve transformacije su optimizovane za ResNet-50 (224x224 input)\")\n",
    "print(\"ğŸ¨ Augmentacija pomaÅ¾e da model generalizuje bolje\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### ZakljuÄak\n",
    "\n",
    "Dataset je uspeÅ¡no pripremljen za maÅ¡insko uÄenje:\n",
    "\n",
    "#### âœ… Prednosti:\n",
    "- Veliki broj slika (~79,000)\n",
    "- Raznovrstan skup proizvoÄ‘aÄa i modela\n",
    "- SpreÄen data leakage (make-model podela)\n",
    "- Brzo uÄitavanje pomoÄ‡u cache sistema (60x brÅ¾e)\n",
    "- Kvalitetne transformacije za augmentaciju\n",
    "\n",
    "#### âš ï¸ Identifikovani izazovi:\n",
    "- ZnaÄajna nebalansiranost klasa (posebno modeli)\n",
    "- Veliki broj modela (1300+) sa malo uzoraka\n",
    "- KombinatoriÄka eksplozija (600,000+ teorijskih kombinacija)\n",
    "- Vrlo nizak random baseline za EMR (~0.00005%)\n",
    "\n",
    "#### ğŸ”„ SledeÄ‡i korak:\n",
    "PokuÅ¡aj treniranja ResNet-50 modela i identifikacija problema u performansama."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Car Recognition (venv)",
   "language": "python",
   "name": "car_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
